{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"VGG16異常検知.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1566609585956,"user_tz":-540,"elapsed":3470,"user":{"displayName":"Shinichiro Futakuchi","photoUrl":"","userId":"16790243129379089608"}},"id":"p30mdHO1i1TO","outputId":"bb2d9fda-8aa2-463e-e997-542e15a39a87","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import keras\n","from keras.applications import VGG16\n","from keras.models import Sequential, load_model, model_from_json\n","from keras import models, optimizers, layers\n","from keras.optimizers import SGD\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from sklearn.model_selection import train_test_split  \n","from PIL import Image \n","from keras.preprocessing import image as images\n","from keras.preprocessing.image import array_to_img, img_to_array, load_img\n","from keras import backend as K \n","import os\n","import numpy as np  \n","import glob  \n","import pandas as pd\n","import cv2"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1566609585964,"user_tz":-540,"elapsed":3463,"user":{"displayName":"Shinichiro Futakuchi","photoUrl":"","userId":"16790243129379089608"}},"id":"GMwFASwKka0E","outputId":"a2c0f6ea-5c78-4776-d7c4-71011d91f85d","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import keras\n","print(keras.__version__) # 2.1.5"],"execution_count":2,"outputs":[{"output_type":"stream","text":["2.2.4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7PZN1NuYNIxD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":139},"outputId":"21665b9c-f8f0-4a79-c967-0c3893f49796","executionInfo":{"status":"ok","timestamp":1566609601762,"user_tz":-540,"elapsed":19231,"user":{"displayName":"Shinichiro Futakuchi","photoUrl":"","userId":"16790243129379089608"}}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","%cd ./gdrive/'My Drive'/\"Colab Notebooks\""],"execution_count":3,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n","/content/gdrive/My Drive/Colab Notebooks\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"gCADTIqmn_97","colab":{}},"source":["from tqdm import tqdm"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1566609957019,"user_tz":-540,"elapsed":373023,"user":{"displayName":"Shinichiro Futakuchi","photoUrl":"","userId":"16790243129379089608"}},"id":"nXAYzT6-i5YF","outputId":"4106d7a9-1cb9-4509-da4d-0f566b4bf502","colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["num_classes = 2\n","folder = [\"Class1\",\"Class1_def\"]                                     \n","image_size = 224\n","x = []\n","y = []\n","\n","for index, name in enumerate(folder):\n","    dir = \"./DAGM/\" + name\n","    files = glob.glob(dir + \"/*.png\")    \n","    for file in tqdm(files):\n","        image = Image.open(file)                       \n","        image = image.convert(\"RGB\")    \n","        image = image.resize((image_size, image_size))\n","        data = np.asarray(image)        \n","        x.append(data)  \n","        y.append(index) \n","\n","x = np.array(x)   \n","y = np.array(y)  \n","\n","x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=111)\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_test /= 255\n","\n","# ｙ　ラベルをワンホット表現に\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)\n","\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')"],"execution_count":5,"outputs":[{"output_type":"stream","text":["100%|██████████| 1000/1000 [05:06<00:00,  4.23it/s]\n","100%|██████████| 150/150 [00:44<00:00,  3.71it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["920 train samples\n","230 test samples\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"NhXJDhZEky55","colab":{"base_uri":"https://localhost:8080/","height":918},"outputId":"9745ad71-0682-4d55-8ee3-01b8017490f5","executionInfo":{"status":"ok","timestamp":1566609985322,"user_tz":-540,"elapsed":1505,"user":{"displayName":"Shinichiro Futakuchi","photoUrl":"","userId":"16790243129379089608"}}},"source":["vgg_conv = VGG16(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n","last = vgg_conv.output\n","\n","mod = Flatten()(last)\n","mod = Dense(1024, activation='relu')(mod)\n","mod = Dropout(0.5)(mod)\n","preds = Dense(2, activation='sigmoid')(mod)\n","\n","model = models.Model(vgg_conv.input, preds)\n","model.summary()\n","\n","epochs = 100\n","batch_size = 48\n","\n","model.compile(loss='binary_crossentropy',\n","              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n","              metrics=['accuracy'])"],"execution_count":7,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_2 (InputLayer)         (None, 224, 224, 3)       0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n","_________________________________________________________________\n","flatten_2 (Flatten)          (None, 25088)             0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 1024)              25691136  \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 1024)              0         \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 2)                 2050      \n","=================================================================\n","Total params: 40,407,874\n","Trainable params: 40,407,874\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"4qH1Ppnpky8E","colab":{"base_uri":"https://localhost:8080/","height":68},"outputId":"0869ff7d-e67a-4716-d751-aa7f023ea761"},"source":["history = model.fit(x_train, y_train,\n","                    batch_size=batch_size,\n","                    epochs=epochs,\n","                    validation_data=(x_test, y_test),\n","                    shuffle=True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 920 samples, validate on 230 samples\n","Epoch 1/100\n"," 96/920 [==>...........................] - ETA: 25:52 - loss: 0.9461 - acc: 0.3125"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"RV7vI8lSky-X","colab":{}},"source":["scores = model.evaluate(x_test, y_test, verbose=1)\n","print('Test loss:', scores[0])\n","print('Test accuracy:', scores[1])\n","\n","### Plot accuracy & loss\n","import matplotlib.pyplot as plt \n","\n","acc = history.history[\"acc\"]\n","val_acc = history.history[\"val_acc\"]\n","loss = history.history[\"loss\"]\n","val_loss = history.history[\"val_loss\"]\n","epochs = range(1, len(acc) + 1)\n","\n","#plot accuracy\n","plt.plot(epochs, acc, label = \"Training acc\" )\n","plt.plot(epochs, val_acc, label = \"Validation acc\")\n","plt.title(\"Training and Validation accuracy\")\n","plt.legend()\n","plt.show()\n","\n","#plot loss\n","plt.plot(epochs, loss,  label = \"Training loss\" )\n","plt.plot(epochs, val_loss, label = \"Validation loss\")\n","plt.title(\"Training and Validation loss\")\n","plt.legend()\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"FCofS-qakzAY","colab":{}},"source":["model.save_weights('grad_vgg16_weight_DAGM_C1.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"wyiBk8n2kzCq","colab":{}},"source":["K.set_learning_phase(1) #set learning phase\n","\n","def Grad_Cam(input_model, pic_array, layer_name):\n","\n","    # 前処理\n","    pic = np.expand_dims(pic_array, axis=0)\n","    pic = pic.astype('float32')\n","    preprocessed_input = pic / 255.0\n","\n","    # 予測クラスの算出\n","    predictions = input_model.predict(preprocessed_input)\n","    class_idx = np.argmax(predictions[0])\n","    class_output = input_model.output[:, class_idx]\n","\n","    #  勾配を取得\n","    conv_output = input_model.get_layer(layer_name).output   # layer_nameのレイヤーのアウトプット\n","    grads = K.gradients(class_output, conv_output)[0]  # gradients(loss, variables) で、variablesのlossに関しての勾配を返す\n","    gradient_function = K.function([input_model.input], [conv_output, grads])  # input_model.inputを入力すると、conv_outputとgradsを出力する関数\n","\n","    output, grads_val = gradient_function([preprocessed_input])\n","    output, grads_val = output[0], grads_val[0]\n","\n","    # 重みを平均化して、レイヤーのアウトプットに乗じる\n","    weights = np.mean(grads_val, axis=(0, 1))\n","    cam = np.dot(output, weights)\n","\n","    # 画像化してヒートマップにして合成\n","    cam = cv2.resize(cam, (224, 224), cv2.INTER_LINEAR) \n","    cam = np.maximum(cam, 0) \n","    cam = cam / cam.max()\n","\n","    jetcam = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)  # モノクロ画像に疑似的に色をつける\n","    jetcam = cv2.cvtColor(jetcam, cv2.COLOR_BGR2RGB)  # 色をRGBに変換\n","    jetcam = (np.float32(jetcam) + pic / 2)   # もとの画像に合成\n","    return jetcam"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"E6XM1j99kzEu","colab":{}},"source":["pic_array = img_to_array(load_img('DAGM/Class1_def/12.png', target_size=(224, 224)))\n","pic = pic_array.reshape((1,) + pic_array.shape)\n","array_to_img(pic_array)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"LnoQE5CDkzG0","colab":{}},"source":["picture = Grad_Cam(model, pic_array, 'block5_conv3')\n","picture = picture[0,:,:,]\n","array_to_img(picture)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Hxogf-WLkzI4","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}